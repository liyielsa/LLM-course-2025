# -*- coding: utf-8 -*-
"""gemini_prompting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10REQrGxuRzCfTtUNWpPKdRCK21Fx6DOX

# Prompting with Gemini
Notebook for experimenting different promting techniques with Gemini

Install the required dependencies with the following command.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install google-generativeai

"""Import the required libraries."""

import google.generativeai as genai
import os

"""Insert your Gemini API key to the following command and import the Gemini model."""

# API_KEY = os.environ.get("GEMINI_API_KEY")
API_KEY = "" # insert API key in this function call with your own API key from aistudio.google.com
genai.configure(api_key=API_KEY)

for m in genai.list_models():
    if 'generateContent' in m.supported_generation_methods:
        print(m.name)

LLM = "gemini-2.5-flash"
model = genai.GenerativeModel(LLM)

"""Modify the `system_prompt` to experiment with different prompting approaches."""

system_prompt = "Write an instruction for a capsule espresso machine. The text should be authoritative and user-centric."

"""We create a list of messages so that we keep history in the context. If you want to clear the messages later in this notebook, add the line `messages = []` to a new line cell in the notebook."""

messages = []
messages.append(system_prompt)

"""Get the response from Gemini model by providing the prompt in a messages list to it."""

r = model.generate_content(messages).text

"""Print the output of the model."""

print("Results of zero-shot prompting: \n")
print(r)

"""Let's define a new prompt."""

user_input = "Write an instruction for a capsule espresso machine. The text could be similar to “The first step is to place the encapsulation plate on top of the cap plate. Place the encapsulation plate on top of the body plate.”"

"""Let's add athe new prompt to the messages list."""

messages.append(user_input)

"""Again we generate the output with the Gemini model."""

r = model.generate_content(messages).text

"""... and print the output."""

print(r)

Chain-of-thought prompting

user_input = "Q: Write an instruction for a water boiler. A: Instruction texts should be instructional and authoritative. This instruction should be user-centric and brief. The instruction could be: To use a water boiler, fill with cold water ( between min/max marks), close lid securely, plug in, and switch on; it automatically heats and often keeps warm, shutting off when done, but always ensure lid is locked and leave some water to prevent dry-boil, unplugging to clean the tank periodically. Q: Write an instruction for a capsule espresso machine."

messages.append(user_input)

r = model.generate_content(messages).text

print(r)